{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration Site Identification \n",
    "- align using BSBolt v0.1.2\n",
    "- minimum alignment score = L,160,0 or 160\n",
    "- 150 bp PE sequencing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# import third party libraries\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local libraries\n",
    "from IntegrationSiteSearch.CallIntegrationSites import CallConsensusIntegrationSites\n",
    "from IntegrationSiteSearch.DetectIntegration import ProcessVectorSpanningReads\n",
    "from IntegrationSiteSearch.IntegrationUtils import get_spanning_reads, stream_mapped_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencing_directory = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencing_samples = []\n",
    "\n",
    "with open(f'{sequencing_directory}samples.txt', 'r') as samples:\n",
    "    for sample in samples:\n",
    "        sequencing_samples.append(sample.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_directory = f'{sequencing_directory}alignments/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Plasmid Integration Spanning Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyes = 'pMSGV1_1G4_A_LY_RetroNYESO1'\n",
    "mart = 'pMSGV1_MART1TCR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyes = 'nyes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_error(error):\n",
    "    raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spanning_reads(file_path: str = None, plasmid_names: set = None):\n",
    "    mapped_reads = {}\n",
    "    for sam_read in stream_mapped_reads(file_path, excluded_flags=[2, 4, 10, 1024]):\n",
    "        QNAME, FLAG, RNAME, RNEXT, POS, CIGAR, alignment_score, mapping_reference = sam_read\n",
    "        plasmid_read = RNAME in plasmid_names\n",
    "        if QNAME not in mapped_reads:\n",
    "            mapped_reads[QNAME] = [[sam_read], plasmid_read]\n",
    "        else:\n",
    "            if plasmid_read:\n",
    "                mapped_reads[QNAME][0].append(sam_read)\n",
    "                mapped_reads[QNAME][1] = plasmid_read\n",
    "            else:\n",
    "                mapped_reads[QNAME][0].append(sam_read)\n",
    "    plasmid_reads = {}\n",
    "    for qname, read_group in mapped_reads.items():\n",
    "        if read_group[1]:\n",
    "            for read in read_group[0]:\n",
    "                if read[2][0:3] == 'chr':\n",
    "                    plasmid_reads[qname] = read_group[0]\n",
    "                    break\n",
    "    return plasmid_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_plasmid_reads(file_path, vector_set, return_queue, sample_name):\n",
    "    plasmid_reads = get_spanning_reads(file_path, vector_set)\n",
    "    return_queue.put((sample_name, plasmid_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = mp.Manager()\n",
    "pool = mp.Pool(processes=8)\n",
    "sample_plasmid_reads = manager.Queue()\n",
    "\n",
    "for sample in sequencing_samples:\n",
    "    search_kwargs = dict(file_path=f'{alignment_directory}{sample}.dup.bam', \n",
    "                         vector_set={nyes},\n",
    "                         return_queue=sample_plasmid_reads,\n",
    "                         sample_name=sample)\n",
    "    pool.apply_async(return_plasmid_reads, kwds=search_kwargs, error_callback=propogate_error)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabbd0dd6a3b47c0809cf1daf4f32169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing Samples', max=48, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=len(sequencing_samples), desc='Processing Samples')\n",
    "\n",
    "completed_samples = 0\n",
    "\n",
    "while len(pool._cache):\n",
    "    update_number = len(sequencing_samples) - len(pool._cache) - completed_samples\n",
    "    pbar.update(update_number)\n",
    "    completed_samples += update_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_reads = {}\n",
    "\n",
    "while not sample_plasmid_reads.empty():\n",
    "    sample, reads = sample_plasmid_reads.get()\n",
    "    integration_reads[sample] = reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_plasmid_reads = dict(integration_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d0338fa8b54db1ae72f36881e6e33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean mapping reads to only include read that map to the appropriate vector\n",
    "cleaned_vector_reads = {}\n",
    "\n",
    "for sample in tqdm(sequencing_samples):\n",
    "    plasmid_reads = sample_plasmid_reads[sample]\n",
    "    cleaned_plasmid_reads = {}\n",
    "    vector = nyes\n",
    "    if sample[0] == 'F':\n",
    "        vector = nyes\n",
    "    for read_name, read_group in plasmid_reads.items():\n",
    "        cleaned_group = []\n",
    "        vector_mapping = False\n",
    "        for read in read_group:\n",
    "            if read[2][0:3] == 'chr':\n",
    "                cleaned_group.append(read)\n",
    "            elif read[2] == vector:\n",
    "                vector_mapping = True\n",
    "                cleaned_group.append(read)\n",
    "        if vector_mapping:\n",
    "            cleaned_plasmid_reads[read_name] = cleaned_group\n",
    "    cleaned_vector_reads[sample] = cleaned_plasmid_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Integration Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1e79bb1fb24687b997a7621b0c6bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int_processor = ProcessVectorSpanningReads(multibase_threshold=0.05, multiread_threshold=180)\n",
    "\n",
    "integration_sites = {}\n",
    "\n",
    "for sample in tqdm(sequencing_samples):\n",
    "    sample_integration_sites = []\n",
    "    for read_label, read_group in cleaned_vector_reads[sample].items():\n",
    "        vector = nyes\n",
    "        if sample[0] == 'F':\n",
    "            vector = nyes\n",
    "        called_int = int_processor.get_integration_sites(read_group, vector=vector)\n",
    "        if called_int:\n",
    "            sample_integration_sites.append(called_int)\n",
    "    integration_sites[sample] = sample_integration_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "homology_regions = [('chr14', 22052000, 22550975), ('chr7', 142328000, 142802725), ('chr7_KI270803v1_alt', 290000, 824901)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_homology(site, homology_regions):\n",
    "    for region in homology_regions:\n",
    "        if site[2] == region[0] and region[1] <= site[3] <= region[2]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_integration_sites = {}\n",
    "\n",
    "for sample, sites in integration_sites.items():\n",
    "    cleaned_values = []\n",
    "    for site in sites:\n",
    "        if site[-1] < 800 or site[-1] > 3800:\n",
    "            if not assess_homology(site, homology_regions):\n",
    "                cleaned_values.append(site)\n",
    "    cleaned_integration_sites[sample] = cleaned_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyes_annotations = {'SD': (2107, 2120),\n",
    " '3_LTR': (5261, 5775),\n",
    " '5_LTR': (1531, 2044),\n",
    " 'SA': (3056, 3080),\n",
    " '1G4_alpha': (3343, 4164),\n",
    " '1G4_beta': (4246, 5181),\n",
    " 'P2A': (4189, 4245),\n",
    " 'Furin': (4165, 4176),\n",
    " 'SGSG': (4177, 4188),\n",
    " 'M13_fwd': (1106, 1123),\n",
    " 'ColE1_origin': (6308, 6990),\n",
    " 'LacZ_alpha': (967, 1035),\n",
    " 'LacO': (5946, 5968),\n",
    " 'AmpR': (7088, 330),\n",
    " 'MSCV_Prom_1': (5260, 5641),\n",
    " 'MSCV_Prom_2': (1529, 1910),\n",
    " 'Retro_NYESO1_F': (4114, 4134),\n",
    " 'Retro_NYESO1_R': (4210, 4224),\n",
    " '2A_Junction_Probe': (4162, 4183),\n",
    " 'Primer_Cloning_1': (4024, 4044),\n",
    " 'Primer_Cloning_2': (4295, 4315)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD [857, 870]\n",
      "3_LTR [4011, 4525]\n",
      "5_LTR [281, 794]\n",
      "SA [1806, 1830]\n",
      "1G4_alpha [2093, 2914]\n",
      "1G4_beta [2996, 3931]\n",
      "P2A [2939, 2995]\n",
      "Furin [2915, 2926]\n",
      "SGSG [2927, 2938]\n",
      "M13_fwd [None, None]\n",
      "ColE1_origin [None, None]\n",
      "LacZ_alpha [None, None]\n",
      "LacO [4696, 4718]\n",
      "AmpR [None, None]\n",
      "MSCV_Prom_1 [4010, 4391]\n",
      "MSCV_Prom_2 [279, 660]\n",
      "Retro_NYESO1_F [2864, 2884]\n",
      "Retro_NYESO1_R [2960, 2974]\n",
      "2A_Junction_Probe [2912, 2933]\n",
      "Primer_Cloning_1 [2774, 2794]\n",
      "Primer_Cloning_2 [3045, 3065]\n"
     ]
    }
   ],
   "source": [
    "cut_nyes_annotations = {}\n",
    "\n",
    "for annotation, span in nyes_annotations.items():\n",
    "    adjusted_span = []\n",
    "    for x in span:\n",
    "        if x < 1250 or x > 6000:\n",
    "            adjusted_span.append(None)\n",
    "        else:\n",
    "            adjusted_span.append(x - 1250)\n",
    "    print(annotation, adjusted_span)\n",
    "    if all(adjusted_span):\n",
    "        cut_nyes_annotations[annotation] = tuple(adjusted_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SD': (857, 870),\n",
       " '3_LTR': (4011, 4525),\n",
       " '5_LTR': (281, 794),\n",
       " 'SA': (1806, 1830),\n",
       " '1G4_alpha': (2093, 2914),\n",
       " '1G4_beta': (2996, 3931),\n",
       " 'P2A': (2939, 2995),\n",
       " 'Furin': (2915, 2926),\n",
       " 'SGSG': (2927, 2938),\n",
       " 'LacO': (4696, 4718),\n",
       " 'MSCV_Prom_1': (4010, 4391),\n",
       " 'MSCV_Prom_2': (279, 660),\n",
       " 'Retro_NYESO1_F': (2864, 2884),\n",
       " 'Retro_NYESO1_R': (2960, 2974),\n",
       " '2A_Junction_Probe': (2912, 2933),\n",
       " 'Primer_Cloning_1': (2774, 2794),\n",
       " 'Primer_Cloning_2': (3045, 3065)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_nyes_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aff6bf3d34401eae59f4640d5d387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_integration_peaks = {}\n",
    "\n",
    "caller = CallConsensusIntegrationSites(region_size=1000, minimum_observations=0)\n",
    "\n",
    "for sample in tqdm(sequencing_samples):\n",
    "    sample_integration_peaks[sample] = caller.call_integration_sites(cleaned_integration_sites[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = pd.DataFrame(sample_integration_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_peaks = {}\n",
    "\n",
    "for sample, peaks in sample_integration_peaks.items():\n",
    "    cleaned_values = {}\n",
    "    for site, peak_info in peaks.items():\n",
    "        if peak_info[-1] < 800 or peak_info[-1] > 3800:\n",
    "            cleaned_values[site] = peak_info\n",
    "    cleaned_peaks[sample] = cleaned_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('integration_peaks.bed', 'w') as out:\n",
    "    for sample, values in cleaned_peaks.items():\n",
    "        for peak in values:\n",
    "            chrom, pos = peak.split(':')\n",
    "            start, end = [int(x) for x in pos.split('-')]\n",
    "            out.write(f'{chrom}\\t{start}\\t{end}\\t{sample}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_sites = []\n",
    "\n",
    "for sample, sites in cleaned_peaks.items():\n",
    "    for site, site_info in sites.items():\n",
    "        chrom, pos = site.split(':')\n",
    "        start, end = pos.split('-')\n",
    "        site_annotation = 'NA'\n",
    "        for annotation, span in cut_nyes_annotations.items():\n",
    "            if span[0] <= site_info[2] <= span[1]:\n",
    "                site_annotation = annotation\n",
    "                break\n",
    "        formatted_sites.append(f'{sample}\\t{chrom}\\t{start}\\t{end}\\t{site_info[0]}\\t{site_info[1]}\\t{site_info[2]}\\t{site_annotation}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('integration_sites.tsv', 'w') as out:\n",
    "    out.write(f'Sample\\tChrom\\tStart\\tEnd\\tAveragePos\\tSupportingReads\\tVectorPos\\tVectorAnnotation\\n')\n",
    "    for line in formatted_sites:\n",
    "        out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('day_0_integration_sites.bed', 'w') as out:\n",
    "    with open('integration_peaks.bed', 'r') as sites:\n",
    "        for site in sites:\n",
    "            site_split = site.strip().split('\\t')\n",
    "            day = site_split[-1].split('_')[2]\n",
    "            if day == '0':\n",
    "                out.write(site)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}